{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85995f60-1839-4667-ac9e-d8c7d5ee3bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c0c08d-9b7e-49eb-9361-ddd3911270f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = load_model()\n",
    "model.tokenizer = tokenizer  # decode에 사용하기 위해 tokenizer 주입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "837da4c7-d664-40a9-b3e7-0b6978c87139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_ansi(r, g, b):\n",
    "    return f\"\\033[38;2;{r};{g};{b}m\"\n",
    "\n",
    "def bg_rgb_ansi(r, g, b):\n",
    "    return f\"\\033[48;2;{r};{g};{b}m\"  # 배경색\n",
    "\n",
    "def color_by_prob(text, prob):\n",
    "    \"\"\"\n",
    "    확률(prob) 값에 따라 색상을 입힌 문자열 반환\n",
    "    높은 확률일수록 초록색, 낮을수록 빨간색 계열\n",
    "    \"\"\"\n",
    "    if prob >= 0.5:\n",
    "        color = \"\\033[92m\"  # 밝은 초록 (high prob)\n",
    "    elif prob >= 0.2:\n",
    "        color = \"\\033[93m\"  # 밝은 노랑 (medium prob)\n",
    "    else:\n",
    "        color = \"\\033[91m\"  # 밝은 빨강 (low prob)\n",
    "\n",
    "    reset = \"\\033[0m\"\n",
    "    return f\"{color}{text}{reset}\"\n",
    "\n",
    "def get_yellow_to_green_ansi(prob):\n",
    "    \"\"\"\n",
    "    확률에 따라 진한 노랑(255,255,0) → 초록(0,255,0) 색상 매핑\n",
    "    \"\"\"\n",
    "    steps = 10\n",
    "    index = min(int(prob * steps), steps - 1)\n",
    "\n",
    "    r_start, g, b = 255, 255, 0  # 시작 색 (노랑)\n",
    "    r_end = 0                   # 끝 색 (초록)\n",
    "    \n",
    "    # R을 선형적으로 감소\n",
    "    r = int(r_start - (r_start - r_end) * (index / (steps - 1)))\n",
    "    \n",
    "    return rgb_ansi(r, g, b)\n",
    "\n",
    "def get_yellow_to_green_bg_ansi(prob):\n",
    "    steps = 10\n",
    "    index = min(int(prob * steps), steps - 1)\n",
    "    r_start, g, b = 255, 255, 0\n",
    "    r = int(r_start - (r_start * index / (steps - 1)))\n",
    "    return bg_rgb_ansi(r, g, b)\n",
    "\n",
    "def get_yellow_to_green_bg_ansi(prob):\n",
    "    steps = 10\n",
    "    index = min(int(prob * steps), steps - 1)\n",
    "    r_start, g, b = 255, 255, 0\n",
    "    r = int(r_start - (r_start * index / (steps - 1)))\n",
    "    return bg_rgb_ansi(r, g, b)\n",
    "\n",
    "def get_yellow_to_brightblue_bg_ansi(prob):\n",
    "    \"\"\"\n",
    "    prob: 0.0(노랑) → 1.0(밝은 파랑) 배경색 10단계 반환\n",
    "    밝은 파랑: #6699FF (R=102,G=153,B=255)\n",
    "    노랑: #FFFF00 (R=255,G=255,B=0)\n",
    "    \"\"\"\n",
    "    steps = 10\n",
    "    index = min(int(prob * steps), steps - 1)\n",
    "    \n",
    "    r_start, g_start, b_start = 255, 255, 0       # 노랑\n",
    "    r_end, g_end, b_end = 102, 153, 255           # 밝은 파랑\n",
    "    \n",
    "    r = int(r_start + (r_end - r_start) * index / (steps - 1))\n",
    "    g = int(g_start + (g_end - g_start) * index / (steps - 1))\n",
    "    b = int(b_start + (b_end - b_start) * index / (steps - 1))\n",
    "    \n",
    "    return bg_rgb_ansi(r, g, b)\n",
    "\n",
    "def get_yellow_to_lightblue_bg_ansi(prob):\n",
    "    \"\"\"\n",
    "    prob: 0.0 (#E5E200 노랑) → 1.0 (#008FE6 파랑) 배경색 10단계 선형 보간\n",
    "    \"\"\"\n",
    "    steps = 10\n",
    "    index = min(int(prob * steps), steps - 1)\n",
    "\n",
    "    r_start, g_start, b_start = 229, 226, 0     # #E5E200 노랑\n",
    "    r_end, g_end, b_end = 0, 143, 230           # #008FE6 파랑\n",
    "\n",
    "    r = int(r_start + (r_end - r_start) * index / (steps - 1))\n",
    "    g = int(g_start + (g_end - g_start) * index / (steps - 1))\n",
    "    b = int(b_start + (b_end - b_start) * index / (steps - 1))\n",
    "\n",
    "    return bg_rgb_ansi(r, g, b)\n",
    "\n",
    "\n",
    "def bg_rgb_ansi(r, g, b):\n",
    "    return f\"\\033[48;2;{r};{g};{b}m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e99b176-8288-400f-b82d-f70789f36d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_tokens(top_tokens, field_width=20):\n",
    "    \"\"\"Top-5 토큰 정보를 가운데 정렬 + 배경색 노랑→초록, 글자색 기본 유지\"\"\"\n",
    "\n",
    "    formatted = []\n",
    "    for _, token_str, prob in top_tokens:\n",
    "        token_display = f\"{repr(token_str)} ({prob:.4f})\"\n",
    "        padded = f\"{token_display:^{field_width}}\"   # 먼저 순수 텍스트로 정렬\n",
    "        bg_color = get_yellow_to_lightblue_bg_ansi(prob) # 외부 정의 함수 호출\n",
    "        colored = f\"{bg_color}{padded}\\033[0m\"       # 색상 코드 감싸기\n",
    "        formatted.append(colored)\n",
    "\n",
    "    print(\"== Top-5 Tokens ==\")\n",
    "    print(\" | \".join(formatted))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50203565-f3f4-4dbc-9941-bd4679102e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_id=\"Qwen/Qwen3-0.6B\", dtype=torch.float16):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=dtype\n",
    "    )\n",
    "    model.eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "def generate_next_token(model, input_ids):\n",
    "    \"\"\"다음 토큰과 top-5 후보 반환\"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    next_token_logits = logits[0, -1, :]\n",
    "    probs = F.softmax(next_token_logits, dim=-1)\n",
    "\n",
    "    # Top-5 토큰 추출\n",
    "    top_probs, top_ids = torch.topk(probs, k=5)\n",
    "    top_tokens = [(token_id.item(), token_str, top_probs[i].item())\n",
    "                  for i, token_id in enumerate(top_ids)\n",
    "                  for token_str in [model.tokenizer.decode(token_id)]]\n",
    "\n",
    "    return top_tokens\n",
    "\n",
    "def run_inference_loop(tokenizer, model, input_text, max_new_tokens=20):\n",
    "    \"\"\"전체 생성 루프 실행\"\"\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    generated = input_ids\n",
    "\n",
    "    print(f\"Input: {input_text}\\n\")\n",
    "\n",
    "    for step in range(max_new_tokens):\n",
    "        top_tokens = generate_next_token(model, generated)\n",
    "        print_top_tokens(top_tokens)\n",
    "\n",
    "        # 다음 토큰 선택 (top-1 기반, greedy)\n",
    "        next_token_id = torch.tensor([[top_tokens[0][0]]], device=model.device)\n",
    "        generated = torch.cat([generated, next_token_id], dim=1)\n",
    "\n",
    "        if next_token_id.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "\n",
    "    output_text = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "    print(\"== Final Output ==\")\n",
    "    print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4db778d-4fe2-4726-8e9d-3b902ea5f1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: What is 2 + 2? Answer briefly.\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;178;207;51m    ' ' (0.2024)    \u001b[0m | \u001b[48;2;203;216;25m  ' The' (0.1626)   \u001b[0m | \u001b[48;2;229;226;0m  ' What' (0.0780)  \u001b[0m | \u001b[48;2;229;226;0m  ' \\n\\n' (0.0721)  \u001b[0m | \u001b[48;2;229;226;0m   ' A' (0.0369)    \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;50;161;178m    '2' (0.7310)    \u001b[0m | \u001b[48;2;229;226;0m    '1' (0.0670)    \u001b[0m | \u001b[48;2;229;226;0m    '3' (0.0307)    \u001b[0m | \u001b[48;2;229;226;0m    ' ' (0.0207)    \u001b[0m | \u001b[48;2;229;226;0m    '4' (0.0137)    \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;50;161;178m   ' +' (0.7778)    \u001b[0m | \u001b[48;2;229;226;0m    '+' (0.0529)    \u001b[0m | \u001b[48;2;229;226;0m   ' is' (0.0316)   \u001b[0m | \u001b[48;2;229;226;0m    '2' (0.0238)    \u001b[0m | \u001b[48;2;229;226;0m  ' plus' (0.0169)  \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;0;143;230m    ' ' (0.9927)    \u001b[0m | \u001b[48;2;229;226;0m    '2' (0.0014)    \u001b[0m | \u001b[48;2;229;226;0m   ' (' (0.0009)    \u001b[0m | \u001b[48;2;229;226;0m' something' (0.0008)\u001b[0m | \u001b[48;2;229;226;0m   ' ?' (0.0005)    \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;0;143;230m    '2' (0.9551)    \u001b[0m | \u001b[48;2;229;226;0m    '3' (0.0251)    \u001b[0m | \u001b[48;2;229;226;0m    '1' (0.0109)    \u001b[0m | \u001b[48;2;229;226;0m    '4' (0.0041)    \u001b[0m | \u001b[48;2;229;226;0m    '5' (0.0016)    \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;152;198;76m   ' is' (0.3840)   \u001b[0m | \u001b[48;2;152;198;76m   ' =' (0.3037)    \u001b[0m | \u001b[48;2;203;216;25m ' equals' (0.1527) \u001b[0m | \u001b[48;2;229;226;0m   ' +' (0.0459)    \u001b[0m | \u001b[48;2;229;226;0m  '.\\n\\n' (0.0194)  \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;25;152;204m    ' ' (0.8740)    \u001b[0m | \u001b[48;2;229;226;0m ' equal' (0.0950)  \u001b[0m | \u001b[48;2;229;226;0m   ' a' (0.0047)    \u001b[0m | \u001b[48;2;229;226;0m   '...' (0.0038)   \u001b[0m | \u001b[48;2;229;226;0m  ' the' (0.0029)   \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;0;143;230m    '4' (0.9751)    \u001b[0m | \u001b[48;2;229;226;0m    '2' (0.0107)    \u001b[0m | \u001b[48;2;229;226;0m    '3' (0.0079)    \u001b[0m | \u001b[48;2;229;226;0m    '5' (0.0023)    \u001b[0m | \u001b[48;2;229;226;0m    '1' (0.0015)    \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;127;189;102m  '.\\n\\n' (0.4106)  \u001b[0m | \u001b[48;2;178;207;51m   '.\\n' (0.2866)   \u001b[0m | \u001b[48;2;178;207;51m    '.' (0.2778)    \u001b[0m | \u001b[48;2;229;226;0m    ',' (0.0124)    \u001b[0m | \u001b[48;2;229;226;0m    '?' (0.0024)    \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;203;216;25m   '**' (0.1451)    \u001b[0m | \u001b[48;2;229;226;0m   'The' (0.0881)   \u001b[0m | \u001b[48;2;229;226;0m  'What' (0.0686)   \u001b[0m | \u001b[48;2;229;226;0m  'Okay' (0.0596)   \u001b[0m | \u001b[48;2;229;226;0m   'But' (0.0403)   \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;178;207;51m'Question' (0.2520) \u001b[0m | \u001b[48;2;229;226;0m  'Final' (0.0941)  \u001b[0m | \u001b[48;2;229;226;0m  'Step' (0.0710)   \u001b[0m | \u001b[48;2;229;226;0m 'Answer' (0.0431)  \u001b[0m | \u001b[48;2;229;226;0m    'Q' (0.0278)    \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;101;179;127m  '**\\n' (0.5942)   \u001b[0m | \u001b[48;2;203;216;25m    ':' (0.1702)    \u001b[0m | \u001b[48;2;229;226;0m   '**' (0.0911)    \u001b[0m | \u001b[48;2;229;226;0m   ':**' (0.0579)   \u001b[0m | \u001b[48;2;229;226;0m   '**:' (0.0216)   \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;101;179;127m  'What' (0.5073)   \u001b[0m | \u001b[48;2;203;216;25m  'Which' (0.1030)  \u001b[0m | \u001b[48;2;229;226;0m   'How' (0.0543)   \u001b[0m | \u001b[48;2;229;226;0m   'If' (0.0253)    \u001b[0m | \u001b[48;2;229;226;0m    'A' (0.0234)    \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;25;152;204m   ' is' (0.8574)   \u001b[0m | \u001b[48;2;229;226;0m  ' does' (0.0317)  \u001b[0m | \u001b[48;2;229;226;0m  ' are' (0.0139)   \u001b[0m | \u001b[48;2;229;226;0m ' number' (0.0132) \u001b[0m | \u001b[48;2;229;226;0m   ' do' (0.0117)   \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;50;161;178m    ' ' (0.7261)    \u001b[0m | \u001b[48;2;178;207;51m  ' the' (0.2180)   \u001b[0m | \u001b[48;2;229;226;0m   ' $' (0.0291)    \u001b[0m | \u001b[48;2;229;226;0m  ' $\\\\' (0.0045)   \u001b[0m | \u001b[48;2;229;226;0m   ' a' (0.0031)    \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;76;170;153m    '2' (0.6050)    \u001b[0m | \u001b[48;2;203;216;25m    '3' (0.1603)    \u001b[0m | \u001b[48;2;229;226;0m    '5' (0.0723)    \u001b[0m | \u001b[48;2;229;226;0m    '1' (0.0590)    \u001b[0m | \u001b[48;2;229;226;0m    '4' (0.0504)    \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;25;152;204m   ' +' (0.8232)    \u001b[0m | \u001b[48;2;229;226;0m   ' *' (0.0518)    \u001b[0m | \u001b[48;2;229;226;0m' divided' (0.0163) \u001b[0m | \u001b[48;2;229;226;0m    '2' (0.0142)    \u001b[0m | \u001b[48;2;229;226;0m    '0' (0.0109)    \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;0;143;230m    ' ' (0.9893)    \u001b[0m | \u001b[48;2;229;226;0m   ' (' (0.0050)    \u001b[0m | \u001b[48;2;229;226;0m   ' $' (0.0023)    \u001b[0m | \u001b[48;2;229;226;0m' something' (0.0003)\u001b[0m | \u001b[48;2;229;226;0m   ' ?' (0.0003)    \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;25;152;204m    '2' (0.8770)    \u001b[0m | \u001b[48;2;229;226;0m    '3' (0.0816)    \u001b[0m | \u001b[48;2;229;226;0m    '4' (0.0146)    \u001b[0m | \u001b[48;2;229;226;0m    '5' (0.0119)    \u001b[0m | \u001b[48;2;229;226;0m    '1' (0.0097)    \u001b[0m\n",
      "\n",
      "== Top-5 Tokens ==\n",
      "\u001b[48;2;76;170;153m   ' +' (0.6812)    \u001b[0m | \u001b[48;2;203;216;25m    '?' (0.1362)    \u001b[0m | \u001b[48;2;229;226;0m   '?\\n' (0.0577)   \u001b[0m | \u001b[48;2;229;226;0m  '?\\n\\n' (0.0542)  \u001b[0m | \u001b[48;2;229;226;0m   ' in' (0.0193)   \u001b[0m\n",
      "\n",
      "== Final Output ==\n",
      "What is 2 + 2? Answer briefly. 2 + 2 is 4.\n",
      "\n",
      "**Question**\n",
      "What is 2 + 2 +\n"
     ]
    }
   ],
   "source": [
    "run_inference_loop(tokenizer, model, \"What is 2 + 2? Answer briefly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54674bf9-d390-44cc-ba10-b67bbfa97bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
